{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS - Processamento de dados\n",
    "[Guia do pandas](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)\n",
    "____\n",
    "\n",
    "Dúvidas?\n",
    "* Romero Carvalho: romerofcarvalho (discord)\n",
    "* Allan Suzuki: allansuzuki (discord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topicos\n",
    "1. [Caso prático](#caso-pratico)\n",
    "2. [O que vamos aprender?](#o-que-vamos-aprender)\n",
    "3. [Exercícios](#exer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso prático - 10m  (5min em cada)\n",
    "<br>Concat + merge      (1h)\n",
    "<br>Pivot + melt        (1h)\n",
    "<br>Exercícios          (1h) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso prático <div id=\"caso-pratico\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos considerar uma situação com dados relacionados a clientes, médicos, consultas e procedimentos médicos, cada um armazenado em tabelas separadas. Durante a análise dos dados de clientes e médicos, notamos que algumas informações não estão atualizadas. **O desafio** é que extrair todos os dados novamente levaria bastante tempo de processamento.\n",
    "\n",
    "<!-- `imagem aqui para ilustrar a falta de dados dessas tabelas` -->\n",
    "\n",
    "O que você faria para solucionar este problema?\n",
    "\n",
    "<!--- tempo de espera para ver como resolver --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUÇÃO**:<!-- Diante dessa questão, a equipe decidiu adotar uma abordagem mais prática: em vez de recarregar todos os dados, a ideia é identificar **apenas** as informações que estão faltando e adicioná-las aos dados desatualizados. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante uma reunião estratégica voltada para a identificação de oportunidades e aprimoramentos com os clientes, Alessandra apresentou à equipe de estratégia os resultados de uma enquete pública realizada no site da Unimed e na rua. Esses resultados incluíam dados demográficos (endereço, cidade, estado) e socioeconômicos (renda familiar, tamanho da família, qualidade de vida), bem como a opinião dos participantes em relação à Unimed de 1 a 5, variando de muito ruim a muito bom. No entanto, a equipe enfrentava dificuldades em compreender os insights dos resultados da enquete devido à forma como os dados estavam organizados, já que cada resposta ocupava uma linha e não conseguia visualizar o todo.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>id_pesquisa</th>\n",
    "      <th>nome</th>\n",
    "      <th>idade</th>\n",
    "      <th>renda</th>\n",
    "      <th>satisfacao</th>\n",
    "      <th>recomendacao</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>1</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>40</td>\n",
    "      <td>6</td>\n",
    "      <td>7</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>2</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>56</td>\n",
    "      <td>7</td>\n",
    "      <td>4</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>3</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>32</td>\n",
    "      <td>4</td>\n",
    "      <td>5</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>4</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>16</td>\n",
    "      <td>7</td>\n",
    "      <td>7</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>5</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>72</td>\n",
    "      <td>9</td>\n",
    "      <td>3</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5</th>\n",
    "      <td>6</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>48</td>\n",
    "      <td>2</td>\n",
    "      <td>5</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>6</th>\n",
    "      <td>7</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>48</td>\n",
    "      <td>3</td>\n",
    "      <td>5</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>7</th>\n",
    "      <td>8</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>40</td>\n",
    "      <td>5</td>\n",
    "      <td>7</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>8</th>\n",
    "      <td>9</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>56</td>\n",
    "      <td>3</td>\n",
    "      <td>2</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>9</th>\n",
    "      <td>10</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>32</td>\n",
    "      <td>8</td>\n",
    "      <td>3</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10</th>\n",
    "      <td>11</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>80</td>\n",
    "      <td>10</td>\n",
    "      <td>7</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>11</th>\n",
    "      <td>12</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>48</td>\n",
    "      <td>8</td>\n",
    "      <td>3</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>12</th>\n",
    "      <td>13</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>32</td>\n",
    "      <td>8</td>\n",
    "      <td>3</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>13</th>\n",
    "      <td>14</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>16</td>\n",
    "      <td>9</td>\n",
    "      <td>5</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>14</th>\n",
    "      <td>15</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>56</td>\n",
    "      <td>4</td>\n",
    "      <td>4</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15</th>\n",
    "      <td>16</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>24</td>\n",
    "      <td>5</td>\n",
    "      <td>3</td>\n",
    "      <td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>16</th>\n",
    "      <td>17</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>32</td>\n",
    "      <td>5</td>\n",
    "      <td>6</td>\n",
    "      <td>2</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>17</th>\n",
    "      <td>18</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>16</td>\n",
    "      <td>8</td>\n",
    "      <td>5</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>18</th>\n",
    "      <td>19</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>80</td>\n",
    "      <td>7</td>\n",
    "      <td>2</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>19</th>\n",
    "      <td>20</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>72</td>\n",
    "      <td>9</td>\n",
    "      <td>4</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>20</th>\n",
    "      <td>21</td>\n",
    "      <td>dados omitidos</td>\n",
    "      <td>24</td>\n",
    "      <td>8</td>\n",
    "      <td>6</td>\n",
    "      <td>3</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "O que você faria para reestruturar os dados e gerar insights estratégicos mais rapidamente?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUÇÃO**:<!-- Uma solução eficaz seria reorganizar os dados, pivotando os dados para categorizar por classes socioeconômicas e regiões demográficas. Essa abordagem permitiria visualizar os resultados agregados da opinião pública de maneira mais clara e compreensível. Ao adotar uma perspectiva semelhante à funcionalidade Pivot Table do Excel, a equipe estaria mais familiarizada e apta a extrair insights significativos de maneira mais rápida e eficiente. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O que vamos aprender? <div id=\"o-que-vamos-aprender\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Concat](#Concat)\n",
    "* [Merge](#Merge)\n",
    "* [Groupby](#groupby)\n",
    "* [Pivot](#Pivot)\n",
    "* [Melt](#Melt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Até onde chegamos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;<img src=\"./img/recap_lecture.png\" alt=\"create_notebook\" width=\"400\"/>\n",
    "\n",
    "Aprendemos a trabalhar com diversas funções para:\n",
    "1. carregar dados vindo de fontes externas;\n",
    "2. localizar dados específicos;\n",
    "3. realizar cálculos;\n",
    "4. salvar os dados em outro tipo de arquivo.\n",
    "\n",
    "Perceba que para aplicar cada uma dessas funções, somente é necessário UM único dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Até onde vamos chegar (com este módulo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&ensp;<img src=\"./img/lecture_target.png\" alt=\"lecture_target\" width=\"400\"/>\n",
    "\n",
    "Neste módulo vamos conseguir realizar uniões/manipulações entre duas ou mais dataframes ou estruturar um dataframe para outra forma (tal como os dois casos que vimos no começo do módulo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat \n",
    "Source: Documentation [(+info)](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As vezes, é preciso um novo conjunto de dados a partir de união de outros dados/tabelas. \n",
    "\n",
    "No caso, quando queremos concatenar/unir/empilhar dados num determinado eixo (lembra-se do que significa eixo em DataFrames?), utilizamos a função **pandas.concat** (semelhante a operação UNION do SQL):\n",
    "\n",
    ">pandas.concat(objs, *, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, sort=False, copy=None)\n",
    "<br>&ensp;&ensp;&ensp;&ensp;Concatenate pandas objects along a particular axis.\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Allows optional set logic along the other axes\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Can also add a layer of hierarchical indexing on the concatenation axis, which may be useful if the labels are the same (or overlapping) on the passed axis number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível combinar duas séries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(['a', 'b'])\n",
    "s2 = pd.Series(['c', 'd'])\n",
    "pd.concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem como combinar dois DataFrames com as mesmas colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\n",
    "df2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])\n",
    "pd.concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porém, combinar dois DataFrames que possuem diferentes colunas retorna valores **NaN** (o que é isto mesmo?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\n",
    "df3 = pd.DataFrame([['c', 3, 'cat'], ['d', 4, 'dog']], columns=['letter', 'number', 'animal']) # one more column\n",
    "pd.concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível resetar os índices com o argumento `ignore_index=True`, quando os índices originais não são importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([['a', 1], ['b', 2]], columns=['letter', 'number'])\n",
    "df2 = pd.DataFrame([['c', 3], ['d', 4]], columns=['letter', 'number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível combinar os DataFrames pelos índices (ao invés das colunas) utilizando o argumento `axis=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usar o df1\n",
    "df4 = pd.DataFrame([['bird', 'polly'], ['monkey', 'george']], columns=['animal', 'name']) # new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, também é possível adicionar uma linha a um DataFrame, se a série tiver índices iguais as colunas do DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nova_linha = pd.Series({'letter': 'z', 'number': 111})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Você tem uma tarefa de criar um DataFrame no seguinte formato:\n",
    "<br>\n",
    "<br>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>Name</th>\n",
    "      <th>Class</th>\n",
    "      <th>InsuranceTotalSpent</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Ana</td>\n",
    "      <td>Enterprise</td>\n",
    "      <td>1200</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Lucas</td>\n",
    "      <td>Personal</td>\n",
    "      <td>900</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Isabella</td>\n",
    "      <td>Enterprise</td>\n",
    "      <td>1500</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Thiago</td>\n",
    "      <td>Elite</td>\n",
    "      <td>800</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Gabriela</td>\n",
    "      <td>Personal</td>\n",
    "      <td>1100</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "Em seguida o teu par te mandou o restante dos dados e pediu para uní-los enquanto ele puxava os dados complementares. Os dados adicionais estão no arquivo `dados_adicionais.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Após a primeira entrega dos dados, um novo cliente apareceu nas bases de dados e teu superior pediu prioridade para incluir esse estimado cliente nos teus dados. Você se lembrou do 1o caso prático desta aula e pediu os dados do novo cliente para incluí-lo:\n",
    "> Name: Romero F Carvalho\n",
    "<br> Class: Premium\n",
    "<br> InsuranceTotalSpent: 90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "Source: Documentation [(+info)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas vezes queremos buscar dados adicionais de outro DataFrame que possuem algum interligação / relacionamento entre si. \n",
    "\n",
    "Neste caso, utilizamos a função **pandas.merge** (semelhante a operação JOIN do SQL):\n",
    "\n",
    "<img src=\"https://community.qlik.com/legacyfs/online/87693_all-joins.png\" width=450>\n",
    "<br><br>\n",
    "\n",
    ">DataFrame.merge(right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=None, indicator=False, validate=None)\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Merge DataFrame or named Series objects with a database-style join.\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;A named Series object is treated as a DataFrame with a single named column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos juntar as informações de dois DataFrames que se relacionam por chaves (keys) comuns entre si:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pacientes = pd.DataFrame({'paciente_id': [1, 2, 3], 'idade': [25, 35, 40]})\n",
    "df_exames = pd.DataFrame({'paciente_id': [1, 2, 4], 'resultado': ['Normal', 'Elevado', 'Ausente']})\n",
    "df_pacientes.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos mudar o tipo da união (qual é a união padrão?), utilizamos o parâmetro `how` que aceita os seguintes valores: \n",
    "> how : {‘left’, ‘right’, ‘outer’, ‘inner’, ‘cross’}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pacientes = pd.DataFrame({'paciente_id': [1, 2, 3], 'idade': [25, 35, 40]})\n",
    "df_exames = pd.DataFrame({'paciente_id': [1, 2, 4], 'resultado': ['Normal', 'Elevado', 'Ausente']})\n",
    "df_pacientes.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que, no tipo união `outer`, não há um `paciente_id 4` no `df_pacientes`, por isso não temos a idade dele e, por padrão, nos retorna `NaN`, bem como não temos resultados do exame para o `paciente_id 3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso as colunas-chave não tenham nomes iguais, podemos utilizando os argumentos `left_on` e `right_on`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pacientes = pd.DataFrame({'paciente_id': [1, 2, 3], 'idade': [25, 35, 40]})\n",
    "df_exames_outro = pd.DataFrame({'id_pacientes': [1, 2, 4], 'resultado': ['Normal', 'Elevado', 'Ausente']})\n",
    "df_pacientes.merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se houver colunas que têm o mesmo nome e não serão chave, podemos diferenciá-los pelos argumento suffixes=('rsuff','lsuff'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exames = pd.DataFrame({'paciente_id': [1, 2, 4], 'resultado': ['Normal', 'Elevado', 'Ausente']})\n",
    "df_renovacao_seguro = pd.DataFrame({'paciente_id': [1, 2, 4], 'resultado': ['Aprovado', 'Aprovado', 'Em analise']})\n",
    "#sem suffixes\n",
    "\n",
    "#com suffixes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Teu colega da recepcao pediu os dados das consultas realizadas do arquivo ``. Porém, a tabela não parece conter informações relevantes para um usuário comum. Para resolver isto, uma prática muito comum no SQL é unir tabelas para ter todas as informações em texto, ao invés de códigos.\n",
    "\n",
    "<br> Na pasta 'nome da pasta aqui' temos 3 csvs que trazem dados dos pacientes, medicos e hospitais. Utilize o merge para identificar todas as informações referentes as consultas realizadas e entregar dados legíveis para o teu colega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby <div id=\"groupby\">\n",
    "Source: Documentation [(+info)](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitas vezes, estaremos interessados em aplicar técnicas de agrupamentos de dados, tal como somas ou contagens, aplicados a dados que pertençam ao mesmo grupo. \n",
    "<br><br>Por exemplo: quantas pessoas de <u>cada</u> **departamento** trabalham na empresa XPTO?\n",
    "\n",
    " Para isso, utilizaremos funções como  **DataFrame.groupby()**, semelhante a operação GROUP BY do SQL, e a função [DataFrameGroupBy.agg()](https://pandas.pydata.org/pandas-docs/version/0.22/generated/pandas.core.groupby.DataFrameGroupBy.agg.html), semelhante as opeações de agregamento no SELECT do SQL.\n",
    "\n",
    ">DataFrame.groupby(by=None, axis=_NoDefault.no_default, level=None, as_index=True, sort=True, group_keys=True, observed=_NoDefault.no_default, dropna=True)\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Group DataFrame using a mapper or by a Series of columns.\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;A groupby operation involves some combination of splitting the object, applying a function, and combining the results. This can be used to group large amounts of data and compute operations on these groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre que utilizarmos o groupby, normalmente estamos interessados em agrupar os dados e aplicar uma função de agregamento (ex: max):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'animal': ['Falcon', 'Falcon', 'Parrot', 'Parrot'],\n",
    "                   'speed': [380., 370., 24., 26.]})\n",
    "\n",
    "df.groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que se não dissermos qual é a coluna a ser aplicada a função agg(), é aplicado a todas as colunas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy() #make a copy\n",
    "df2['height'] = [100, 105, 95, 90]  # add new data\n",
    "df.groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível também aplicar uma função criada, desde que seja aplicada para o mesmo tipo de objeto resultante do groupby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_criada(df_qualquer):\n",
    "    \"\"\"\n",
    "    Funcao que recebe um DataFrame a\n",
    "    diferença entre o valor max e o min\n",
    "    \"\"\"\n",
    "    df_min = df_qualquer.min()\n",
    "    df_max = df_qualquer.max()\n",
    "\n",
    "    return df_max-df_min\n",
    "\n",
    "df.groupby()    #não tem ()\n",
    "# df.groupby('animal').agg(func=[max,min,funcao_criada])    #não tem ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Normalmente, após um groupby, temos um objeto do tipo `DataFrameGroupBy`, que é composto por vários DataFrames ou Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df.groupby('animal')\n",
    "print('Tipo da variavel df_grouped:',type(df_groupby))\n",
    "\n",
    "# get one group from groupby\n",
    "for obj_dentro_do_groupby in df_groupby:\n",
    "    \n",
    "    break   # o que acontece se tirar esse`break`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar os dados de casos de covid no mundo se encontra no caminho: support_data/covid_country_latest.csv Quantos `confirmed_cases` por dia aconteciam no mundo inteiro? Qual foi o dia com maior quantidade de `confirmed_cases` e `deaths`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- **Desafio**: Vamos tentar quais foram os top 3 registros por páis com mais `deaths`. Comece primeiro com o dataset inteiro:   -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**PAUSA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot\n",
    "Source: Documentation [(+info)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muitos usuários estão mais acostumados a olhar tabelas parecidas com as planilhas de MS Excel, comumente utilizando as tabelas dinâmicas (ou *pivot table* em inglês). Para transformar nossos dados em formatos parecidos com este, utilizamos a função DataFrame.pivot()\n",
    "\n",
    "> DataFrame.pivot(*, columns, index=_NoDefault.no_default, values=_NoDefault.no_default)\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Return reshaped DataFrame organized by given index / column values.\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Reshape data (produce a “pivot” table) based on column values. Uses unique values from specified index / columns to form axes of the resulting DataFrame. This function does not support data aggregation, multiple values will result in a MultiIndex in the columns. See the User Guide for more on reshaping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realzar o pivot, basta dizer qual(is) a(s) columna(s) para os argumentos:\n",
    "- `index`\n",
    "- `columns` \n",
    "- `values`\n",
    "\n",
    "<!-- `img de um dataset no pivot` -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'animal': ['Elefante', 'Leão', 'Girafa', 'Tigre', 'Pinguim'],\n",
    "    'habitat': ['Savana', 'Savana', 'Savana', 'Floresta', 'Polo Sul'],\n",
    "    'qtd': [10, 15, 8, 12, 20]\n",
    "}\n",
    "\n",
    "df_animais_habitat = pd.DataFrame(data)\n",
    "\n",
    "df_animais_habitat.pivot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que quando não há valores para uma determinada combinação, por padrão retorna (adivinha?) `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso fosse realizado o mesmo levantamento de antes, mas com novos dados, não seria possível utilizar `pivot()` juntando os dados para ter um resultado somado ao anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_levantamentos = pd.DataFrame({\n",
    "    'animal': ['Elefante', 'Leão', 'Girafa', 'Tigre', 'Pinguim','Elefante'],\n",
    "    'habitat': ['Savana', 'Savana', 'Savana', 'Floresta', 'Polo Sul','Floresta'],\n",
    "    'qtd': [5, 10, 15, 8, 25, 10]  # Quantidades diferentes, ultimo é novo registro\n",
    "})\n",
    "\n",
    "# adicionando novos_levantamentos\n",
    "new_df = pd.concat()   # o que isto faz mesmo?\n",
    "\n",
    "new_df.pivot()\n",
    "# uai... pq deu erro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso acontece porque esta função não realiza nenhuma função de agregamento (quais são?) quando temos dados diferentes para a a mesma relação índice-coluna!\n",
    "\n",
    "Nesse caso, devemos utilizar a função DataFrame.pivot_table() com o argumento `aggfunc` com a função de agregamento que queremos.\n",
    "\n",
    "No caso anterior, queríamos somar quando houvesse novos levantamentos para o mesmo grupo, certo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.pivot_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Hands-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembra do **caso prático 2** no ínicio da aula? Vamos simular um dataset para efetuar esta tarefa:\n",
    "\n",
    "Durante uma reunião estratégica voltada para a identificação de oportunidades e aprimoramentos com os clientes, Alessandra apresentou à equipe de estratégia os resultados de uma enquete pública realizada no site da Unimed e na rua. Esses resultados incluíam dados pessoais: nome, idade, renda (em salarios mínimos);\n",
    "e resultados da pesquisa: nível de satisfação e recomendação do serviço.\n",
    "\n",
    "No entanto, a equipe enfrentava dificuldades em compreender os insights dos resultados da enquete devido à forma como os dados estavam organizados, já que cada resposta ocupava uma linha e não conseguia visualizar o todo.\n",
    "\n",
    "O que você faria para reestruturar os dados e gerar insights estratégicos mais rapidamente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simular_resultados_da_pesquisa(nseed:int=42):\n",
    "    \"\"\"\n",
    "    Criando um DataFrame de pesquisa de satisfação.\n",
    "    Retorna um pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    np.random.seed(nseed)  # Definindo semente para reprodutibilidade\n",
    "\n",
    "    # Gerando valores para as colunas\n",
    "    num_participantes = 1000\n",
    "    idades = np.arange(16, 81, 8)\n",
    "    rendas = np.arange(1, 11, 1)\n",
    "    satisfacao = np.random.randint(1, 8, size=num_participantes)\n",
    "    recomendacao = np.random.randint(1, 4, size=num_participantes)\n",
    "\n",
    "    # Criando o DataFrame\n",
    "    df_pesquisa = pd.DataFrame({\n",
    "        'id_pesquisa': np.arange(1, num_participantes + 1),\n",
    "        'nome': ['dados omitidos'] * num_participantes,\n",
    "        'idade': np.random.choice(idades, size=num_participantes),\n",
    "        'renda': np.random.choice(rendas, size=num_participantes),\n",
    "        'satisfacao': satisfacao,\n",
    "        'recomendacao': recomendacao\n",
    "    })\n",
    "\n",
    "    return df_pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando precisamos do oposto ao pivot (unpivot), ou seja, quando alguém nos entrega os dados resultantes de um pivot table feito no MS Excel para ser utilizado em uma análise de dados, utilizamos **DataFrame.melt()**.\n",
    "\n",
    ">DataFrame.melt(id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.\n",
    "<br><br>&ensp;&ensp;&ensp;&ensp;This function is useful to reshape a DataFrame into a format where one or more columns are identifier variables (id_vars), while all other columns, considered measured variables (value_vars), are “unpivoted” to the row axis, leaving just two non-identifier columns, ‘variable’ and ‘value’."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar os dados pivotados da seção anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_data = new_df.pivot_table(index='animal',columns='habitat',values='qtd', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos olhar como como é o resultado de um pivot_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('columns:', pivot_data.columns.tolist())\n",
    "# print('index:', pivot_data.index.name)\n",
    "# display(pivot_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meu id_vars (olha os args do melt) ideal são os dados que estão no `index`, que eu não consigo acessar pelos `['']` porque não é uma coluna (olhar e comparar os dados do exemplo na documentação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nao consigo acessar os indices aqui:\n",
    "# pivot_data['animal'] #erro!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, uma forma de obter esses dados é fazer com que o índice vire uma coluna do DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_data.reset_index()['animal']   # faz com que o indice comece do 0, além disso, transforma o indíce anterior em coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_data.reset_index().melt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
